{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe12c203-e6a6-452c-a655-afb8a03a4ff5",
   "metadata": {},
   "source": [
    "# End of week 1 exercise\n",
    "\n",
    "To demonstrate your familiarity with OpenAI API, and also Ollama, build a tool that takes a technical question,  \n",
    "and responds with an explanation. This is a tool that you will be able to use yourself during the course!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1070317-3ed9-4659-abe3-828943230e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from openai import OpenAI\n",
    "from IPython.display import Markdown, display, update_display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a456906-915a-4bfd-bb9d-57e505c5093f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# constants\n",
    "\n",
    "MODEL_GPT = 'gpt-4o-mini'\n",
    "# MODEL_LLAMA = 'llama3.2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a8d7923c-5f28-4c30-8556-342d7c8497c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Openai api key loaded successfully\n"
     ]
    }
   ],
   "source": [
    "# set up environment\n",
    "load_dotenv(override=True)\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "if OPENAI_API_KEY and OPENAI_API_KEY.startswith(\"sk-proj-\") and len(OPENAI_API_KEY) > 10:\n",
    "    print(\"Openai api key loaded successfully\")\n",
    "else:\n",
    "    print(\"Failed to load Openai api key! Please Check .env file.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f0d0137-52b0-47a8-81a8-11a90a010798",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here is the question; type over this to ask something new\n",
    "\n",
    "question = \"\"\"\n",
    "Please explain what this code does and why:\n",
    "yield from {book.get(\"author\") for book in books if book.get(\"author\")}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "60ce7000-a4a5-4cce-a261-e75ef45063b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The provided code is a Python expression that leverages a generator and a set comprehension. Let's break it down step by step.\n",
       "\n",
       "### Breakdown of the Code\n",
       "\n",
       "1. **Set Comprehension**: \n",
       "   ```python\n",
       "   {book.get(\"author\") for book in books if book.get(\"author\")}\n",
       "   ```\n",
       "   - This part generates a set of unique author names from a collection of `books`.\n",
       "   - The `for book in books` loops over each `book` in the `books` iterable.\n",
       "   - `book.get(\"author\")` accesses the value associated with the key `\"author\"` in each `book` dictionary.\n",
       "   - The `if book.get(\"author\")` condition filters out any books that do not have an author (e.g., when the value is `None` or an empty string).\n",
       "   - The result is a set containing unique author names, meaning each author will only appear once even if they have written multiple books.\n",
       "\n",
       "2. **Yielding Values**:\n",
       "   ```python\n",
       "   yield from ...\n",
       "   ```\n",
       "   - `yield from` is used in generator functions to yield all values from an iterable. In this case, it will yield each unique author name generated by the set comprehension one at a time.\n",
       "   - This is often used to simplify the process of yielding multiple values from a generator.\n",
       "\n",
       "### Example\n",
       "\n",
       "Consider the following list of `books`:\n",
       "\n",
       "```python\n",
       "books = [\n",
       "    {\"title\": \"Book 1\", \"author\": \"Author A\"},\n",
       "    {\"title\": \"Book 2\", \"author\": \"Author B\"},\n",
       "    {\"title\": \"Book 3\", \"author\": \"Author A\"},\n",
       "    {\"title\": \"Book 4\", \"author\": None},\n",
       "    {\"title\": \"Book 5\", \"author\": \"Author C\"},\n",
       "]\n",
       "```\n",
       "\n",
       "### Code Usage\n",
       "\n",
       "Assuming the yield statement is part of a generator function, it can be illustrated as follows:\n",
       "\n",
       "```python\n",
       "def get_authors(books):\n",
       "    yield from {book.get(\"author\") for book in books if book.get(\"author\")}\n",
       "```\n",
       "\n",
       "### How It Works\n",
       "\n",
       "- This function, `get_authors`, would yield unique values from the set comprehension when called.\n",
       "- If called like so:\n",
       "\n",
       "```python\n",
       "for author in get_authors(books):\n",
       "    print(author)\n",
       "```\n",
       "\n",
       "### Output\n",
       "The output will be:\n",
       "\n",
       "```\n",
       "Author A\n",
       "Author B\n",
       "Author C\n",
       "```\n",
       "\n",
       "### Summary\n",
       "\n",
       "- The expression extracts unique authors from a list of book dictionaries where the author is not `None` or empty, and it yields each author one by one from a generator. This is a concise and efficient way to process and output a filtered collection of data."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get gpt-4o-mini to answer, with streaming\n",
    "system_prompt = \"\"\"\n",
    "You are an technical expert in reading code.\n",
    "Provide explanation of the technical code question that you get with an example if possible.\n",
    "Respond in markdown and you can include code blocks if required.\n",
    "\"\"\"\n",
    "openai = OpenAI()\n",
    "stream = openai.chat.completions.create(\n",
    "    model=MODEL_GPT,\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": question}\n",
    "    ],\n",
    "    stream=True\n",
    ")\n",
    "response = \"\"\n",
    "display_handle = display(Markdown(\"\"), display_id=True)\n",
    "for chunk in stream:\n",
    "    response += chunk.choices[0].delta.content or \"\"\n",
    "    update_display(Markdown(response), display_id=display_handle.display_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f7c8ea8-4082-4ad0-8751-3301adcf6538",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Llama 3.2 to answer"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-engineering",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
